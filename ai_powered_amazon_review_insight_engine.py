# -*- coding: utf-8 -*-
"""AI-Powered Amazon Review Insight Engine.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sW_7D5NkdsP3KX66rH35cKs0cg9UWWv4

Step 1 ‚Äì Dataset Enrichment and Language Translation

In this step, we simulate a real-world multilingual scenario.
The Amazon Polarity dataset mostly contains English reviews, so I manually inject additional non-English samples (Hindi, French, Spanish).
The system automatically detects each review‚Äôs language, translates it to English using the Google Translate API, and cleans it for later NLP processing.

This ensures our pipeline can generalize to multilingual inputs‚Äîsomething very useful for global e-commerce analytics.
"""

!pip install googletrans==4.0.0-rc1
!pip install langdetect

# ============================================
# üì¶ CHUNK 1: Dataset Enrichment + Translation
# ============================================

import pandas as pd
from datasets import load_dataset
from googletrans import Translator
from langdetect import detect
import random
import re

# Load dataset (small subset for faster processing)
print("üì• Loading Amazon Polarity dataset sample...")
dataset = load_dataset("amazon_polarity")
df = pd.DataFrame(dataset["train"]).sample(1000, random_state=42)
df = df.rename(columns={'content': 'review', 'label': 'sentiment'})
df['sentiment'] = df['sentiment'].map({0: 'Negative', 1: 'Positive'})

# Add multilingual samples manually to show translation
extra_reviews = [
    ("‡§Ø‡§π ‡§â‡§§‡•ç‡§™‡§æ‡§¶ ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§π‡•à, ‡§Æ‡•Å‡§ù‡•á ‡§Ø‡§π ‡§¨‡§π‡•Å‡§§ ‡§™‡§∏‡§Ç‡§¶ ‡§Ü‡§Ø‡§æ!", "Positive"),   # Hindi
    ("Ce produit est vraiment mauvais, je ne le recommande pas.", "Negative"), # French
    ("El sonido es incre√≠ble y la calidad es excelente.", "Positive"),          # Spanish
    ("No me gust√≥ el empaque del producto, parece barato.", "Negative"),       # Spanish
    ("La batterie ne dure pas longtemps, d√©√ßu.", "Negative")                   # French
]

extra_df = pd.DataFrame(extra_reviews, columns=["review", "sentiment"])
df = pd.concat([df, extra_df], ignore_index=True)

# Detect and translate non-English reviews
translator = Translator()
translated_texts = []
detected_languages = []

print("üåê Translating Non-English reviews...")
for text in df["review"]:
    try:
        lang = detect(text)
        detected_languages.append(lang)
        if lang != "en":
            translated_texts.append(translator.translate(text, src=lang, dest="en").text)
        else:
            translated_texts.append(text)
    except Exception:
        detected_languages.append("unknown")
        translated_texts.append(text)

df["detected_language"] = detected_languages
df["translated_review"] = translated_texts

# Cleaning
def clean_text(text):
    text = re.sub(r"[^a-zA-Z\s]", "", text)
    text = re.sub(r"\s+", " ", text)
    return text.lower().strip()

df["clean_review"] = df["translated_review"].apply(clean_text)

# ‚úÖ Display results
print("\n‚úÖ Sample Multilingual Translation Results:")
print(df[["review", "detected_language", "translated_review"]].tail(10))

# Save intermediate dataset
df.to_csv("enriched_reviews.csv", index=False)
print("\nüíæ Enriched dataset saved as 'enriched_reviews.csv'")

"""Step 2 ‚Äì Advanced Text Pre-processing and Visualization

After collecting and translating the reviews, the next step is to clean and normalize the textual data so that it can be processed efficiently by NLP models.
I apply a sequence of transformations‚Äîremoving special characters, lower-casing, tokenization, stop-word elimination, and lemmatization‚Äîto convert each review into its most meaningful linguistic form.

Once the text is standardized, I explore the dataset visually. A word-frequency chart helps identify the most recurrent discussion terms across all reviews, while a word cloud provides an at-a-glance understanding of overall sentiment tone. Finally, a sentiment-distribution plot shows whether the dataset is balanced between positive and negative opinions.

This step not only improves downstream model performance but also yields direct business insights‚Äîhighlighting which product attributes (like quality, price, or service) customers talk about most frequently.
"""

# ============================================================
# üß† CHUNK 2: Advanced Text Pre-processing + Visualization
# ============================================================

import nltk, spacy, re
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from collections import Counter
import matplotlib.pyplot as plt
from wordcloud import WordCloud

# Download necessary resources (safe to re-run)
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')
nlp = spacy.load("en_core_web_sm")

# Load enriched dataset from previous chunk
df = pd.read_csv("enriched_reviews.csv")

# Initialize tools
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    # Remove numbers & special chars
    text = re.sub(r'[^a-zA-Z\s]', '', str(text))
    text = text.lower().strip()
    # Tokenize
    tokens = [t for t in text.split() if t not in stop_words and len(t) > 2]
    # Lemmatize using WordNet
    lemmas = [lemmatizer.lemmatize(t) for t in tokens]
    return " ".join(lemmas)

print("üßπ Cleaning and Lemmatizing Reviews...")
df["processed_review"] = df["clean_review"].apply(preprocess_text)

# ------------------------------------------------------------
# WORD FREQUENCY ANALYSIS
# ------------------------------------------------------------
all_words = " ".join(df["processed_review"]).split()
word_freq = Counter(all_words).most_common(20)

# Plot top 20 frequent words
plt.figure(figsize=(10,5))
plt.bar([w for w,_ in word_freq],[f for _,f in word_freq],color='skyblue')
plt.xticks(rotation=45)
plt.title("Top 20 Most Frequent Words in Reviews")
plt.xlabel("Word")
plt.ylabel("Frequency")
plt.show()

# ------------------------------------------------------------
# WORD CLOUD VISUALIZATION
# ------------------------------------------------------------
text_data = " ".join(df["processed_review"])
wordcloud = WordCloud(width=900, height=400, background_color='white').generate(text_data)

plt.figure(figsize=(12,6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title("Word Cloud of Reviews", fontsize=16)
plt.show()

wordcloud.to_file("wordcloud.png")
print("‚úÖ Wordcloud image saved for PDF reporting.")

# ------------------------------------------------------------
# SENTIMENT DISTRIBUTION
# ------------------------------------------------------------
sentiment_counts = df["sentiment"].value_counts()

plt.figure(figsize=(6,5))
plt.bar(sentiment_counts.index, sentiment_counts.values, color=['lightcoral','lightgreen'])
plt.title("Sentiment Distribution (Dataset Overview)")
plt.xlabel("Sentiment")
plt.ylabel("Number of Reviews")
plt.show()

print("‚úÖ Preprocessing and visualization completed successfully!")

"""Step 2: POS Tagging and Named Entity Recognition (NER)

In this step, we perform Part-of-Speech (POS) Tagging and Named Entity Recognition (NER) ‚Äî two fundamental NLP techniques used to extract grammatical and semantic information from text.

üß† POS Tagging

POS tagging assigns grammatical labels to each word in a sentence such as noun (NN), verb (VB), adjective (JJ), etc. This helps in understanding sentence structure and identifying key linguistic patterns, which are essential for later tasks like sentiment or topic analysis.

üß† Named Entity Recognition (NER)

NER identifies important entities in text such as names, locations, brands, products, or organizations. For example:

‚ÄúAmazon sells Echo in India.‚Äù
Here, Amazon ‚Üí Organization, and India ‚Üí Location.

Together, POS tagging and NER help us derive linguistic and contextual features that add interpretability to sentiment models.
"""

# ============================================
# Step 2: POS Tagging and Named Entity Recognition
# ============================================

import nltk
from nltk import pos_tag, word_tokenize
import spacy
from collections import Counter

# Download required NLTK data
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('averaged_perceptron_tagger')
nltk.download('averaged_perceptron_tagger_eng')

# Load Spacy model for NER
nlp = spacy.load("en_core_web_sm")

# Take sample reviews for analysis
sample_texts = df['translated_review'].sample(3, random_state=42).tolist()

print("üîç Performing POS Tagging with NLTK:\n")
for text in sample_texts:
    tokens = word_tokenize(text)
    tagged = pos_tag(tokens)
    print(f"Sample Review:\n{text}\nPOS Tags:\n{tagged[:10]}\n{'-'*80}")

print("\nüîç Performing Named Entity Recognition (NER) using SpaCy:\n")
for text in sample_texts:
    doc = nlp(text)
    print(f"Sample Review:\n{text}")
    print("Named Entities:", [(ent.text, ent.label_) for ent in doc.ents])
    print("-"*80)

"""**Step** **3: Text Preprocessing and Feature** **Extraction**

In this step, we prepare the text data for machine learning models and extract the most informative features. This includes:

Tokenization: Splitting sentences into words.

Stopword Removal: Removing unimportant words such as ‚Äúthe‚Äù, ‚Äúis‚Äù, ‚Äúand‚Äù, etc.

TF-IDF Vectorization: Measuring how important each word is relative to all reviews.

Word Cloud Visualization: Highlighting the most frequent and meaningful words visually.

By doing this, we can uncover dominant terms that characterize positive and negative sentiments in the Amazon reviews dataset.
"""

# ============================================
# Step 3: Text Preprocessing + Feature Extraction (TF-IDF + Word Cloud)
# ============================================

from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.corpus import stopwords
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter
import nltk

nltk.download('stopwords')

# Define stopwords
stop_words = set(stopwords.words('english'))

# Clean and preprocess text
def preprocess(text):
    tokens = [word.lower() for word in word_tokenize(text) if word.isalpha() and word.lower() not in stop_words]
    return " ".join(tokens)

df['clean_review'] = df['translated_review'].apply(preprocess)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(max_features=1000)
tfidf_matrix = vectorizer.fit_transform(df['clean_review'])
feature_names = vectorizer.get_feature_names_out()

# Word frequency analysis
all_words = " ".join(df['clean_review'])
word_freq = Counter(all_words.split())

# WordCloud visualization
plt.figure(figsize=(10,6))
wc = WordCloud(width=800, height=400, background_color='white', colormap='viridis').generate(all_words)
plt.imshow(wc, interpolation='bilinear')
plt.axis('off')
plt.title("Word Cloud of Amazon Reviews", fontsize=14)
plt.show()

print("\nüîç Top 15 Most Common Words in Reviews:")
print(dict(word_freq.most_common(15)))

"""Step 4: Sentiment Analysis ‚Äî Lexicon-Based + ML Classifier

In this section, we‚Äôll determine the emotional polarity (positive, negative, or neutral) of each Amazon review using two complementary methods:

Lexicon-Based Approach (VADER):

Uses a rule-based sentiment scoring technique from the NLTK library.

Ideal for short, opinionated sentences such as customer reviews.

Machine Learning Classifier (Logistic Regression):

Converts text into numerical features using TF-IDF.

Trains a predictive model to classify reviews into positive or negative sentiment.

By combining both methods, we get both linguistic interpretability and predictive performance.
"""

# ============================================
# Step 4: Sentiment Analysis (Lexicon + ML-based)
# ============================================

from nltk.sentiment import SentimentIntensityAnalyzer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import seaborn as sns
import numpy as np

nltk.download('vader_lexicon')

# --- Lexicon-Based Sentiment Analysis ---
sia = SentimentIntensityAnalyzer()
df['polarity'] = df['clean_review'].apply(lambda x: sia.polarity_scores(x)['compound'])

# Categorize sentiment based on polarity
def categorize_sentiment(score):
    if score > 0.1:
        return 'Positive'
    elif score < -0.1:
        return 'Negative'
    else:
        return 'Neutral'

df['predicted_sentiment_lexicon'] = df['polarity'].apply(categorize_sentiment)

print("‚úÖ Lexicon-based sentiment analysis completed!")

# --- Machine Learning-Based Sentiment Analysis ---
X = df['clean_review']
y = df['predicted_sentiment_lexicon'].apply(lambda x: 1 if x == 'Positive' else (0 if x == 'Negative' else 2))

# Only keep binary labels for ML classifier
mask = y != 2
X_binary, y_binary = X[mask], y[mask]

X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)

vectorizer = TfidfVectorizer(max_features=3000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

model = LogisticRegression(max_iter=1000)
model.fit(X_train_tfidf, y_train)
y_pred = model.predict(X_test_tfidf)

# --- Evaluation ---
accuracy = accuracy_score(y_test, y_pred)
print(f"\nüéØ Model Accuracy: {accuracy*100:.2f}%\n")
print("üßæ Classification Report:")
print(classification_report(y_test, y_pred, target_names=["Negative", "Positive"]))

# Confusion matrix visualization
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Greens", xticklabels=["Neg", "Pos"], yticklabels=["Neg", "Pos"])
plt.title("Sentiment Classification Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# --- Example Inference ---
example_review = "This product works great and I highly recommend it!"
example_vector = vectorizer.transform([example_review])
pred_label = model.predict(example_vector)[0]
predicted = "Positive" if pred_label == 1 else "Negative"
print(f"\nüí¨ Example Review: {example_review}")
print(f"Predicted Sentiment (ML Model): {predicted}")

# ============================================
# Step 4.1: Enhanced Sentiment Model (Naive Bayes)
# ============================================

from sklearn.naive_bayes import MultinomialNB
from sklearn.utils import resample

# Rebalance data (ensure equal positive and negative samples)
df_balanced = df[df['predicted_sentiment_lexicon'] != 'Neutral']
min_class_size = df_balanced['predicted_sentiment_lexicon'].value_counts().min()

df_balanced = pd.concat([
    resample(df_balanced[df_balanced['predicted_sentiment_lexicon'] == 'Positive'],
             replace=False, n_samples=min_class_size, random_state=42),
    resample(df_balanced[df_balanced['predicted_sentiment_lexicon'] == 'Negative'],
             replace=False, n_samples=min_class_size, random_state=42)
])

X_bal = df_balanced['clean_review']
y_bal = df_balanced['predicted_sentiment_lexicon'].apply(lambda x: 1 if x == 'Positive' else 0)

X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, test_size=0.2, random_state=42)

vectorizer = TfidfVectorizer(max_features=3000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Train Naive Bayes classifier
nb_model = MultinomialNB()
nb_model.fit(X_train_tfidf, y_train)
y_pred_nb = nb_model.predict(X_test_tfidf)

# Evaluate performance
accuracy_nb = accuracy_score(y_test, y_pred_nb)
print(f"üéØ Naive Bayes Model Accuracy: {accuracy_nb*100:.2f}%\n")
print("üßæ Classification Report (Naive Bayes):")
print(classification_report(y_test, y_pred_nb, target_names=["Negative", "Positive"]))

# Confusion matrix visualization
cm_nb = confusion_matrix(y_test, y_pred_nb)
sns.heatmap(cm_nb, annot=True, fmt="d", cmap="Blues", xticklabels=["Neg", "Pos"], yticklabels=["Neg", "Pos"])
plt.title("Enhanced Naive Bayes Sentiment Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# Compare VADER vs Naive Bayes
print("\nüîç Comparison Summary:")
print(f"Lexicon-based Accuracy: {accuracy*100:.2f}%")
print(f"Naive Bayes Accuracy:   {accuracy_nb*100:.2f}%")

# Example inference
example_review = "The product quality is poor and I would not buy it again."
example_vec = vectorizer.transform([example_review])
pred_label = nb_model.predict(example_vec)[0]
predicted = "Positive" if pred_label == 1 else "Negative"
print(f"\nüí¨ Example Review: {example_review}")
print(f"Predicted Sentiment (Enhanced Model): {predicted}")

""" Step 5: Topic Modeling & Semantic Analysis (LSA + LDA + Word2Vec)

Goal:
- Discover latent topics (themes) in the reviews using two complementary approaches:
  1. **LSA** (TF-IDF + TruncatedSVD): fast, deterministic, good for identifying broad themes.
  2. **LDA** (gensim): probabilistic topic model that gives interpretable topic-word distributions.
- Train a lightweight **Word2Vec** model to inspect semantic relations (word similarity).
- Produce:
  - Top keywords per topic (for LSA and LDA),
  - Topic distribution across corpus (how many reviews per topic),
  - Representative reviews per topic,
  - Small semantic probes using Word2Vec.
"""

# ============================================
# Step 5: Topic Modeling & Semantic Analysis
# ============================================
!pip install gensim
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from gensim.corpora import Dictionary
from gensim.models import LdaModel
from gensim import matutils
from gensim.models import Word2Vec
from collections import defaultdict
import matplotlib.pyplot as plt
import seaborn as sns

# Use processed/cleaned reviews column (created earlier)
# df['processed_review'] or df['clean_review'] should exist from previous chunks
text_col = 'processed_review' if 'processed_review' in df.columns else 'clean_review'
docs = df[text_col].astype(str).tolist()
print(f"üîé Running topic analysis on {len(docs)} documents (column: {text_col})")

# -------------------- LSA (TF-IDF + SVD) --------------------
print("\n‚û°Ô∏è LSA (TF-IDF + TruncatedSVD)")

tfidf = TfidfVectorizer(max_features=3000, stop_words='english')
X = tfidf.fit_transform(docs)
terms = tfidf.get_feature_names_out()

n_components = 5
lsa = TruncatedSVD(n_components=n_components, random_state=42)
lsa.fit(X)

def top_terms_per_lsa_component(model, terms, n=10):
    topics = []
    for i, comp in enumerate(model.components_):
        terms_idx = np.argsort(comp)[::-1][:n]
        topic_terms = [terms[t] for t in terms_idx]
        topics.append(topic_terms)
    return topics

lsa_topics = top_terms_per_lsa_component(lsa, terms, n=10)
for i, tterms in enumerate(lsa_topics, 1):
    print(f"\nLSA Topic {i}: {tterms}")

# -------------------- LDA (gensim) --------------------
print("\n‚û°Ô∏è LDA (gensim) ‚Äî building dictionary & corpus")
# Prepare tokens
tokenized = [doc.split() for doc in docs]
# Filter extremes
dictionary = Dictionary(tokenized)
dictionary.filter_extremes(no_below=5, no_above=0.6, keep_n=5000)
corpus = [dictionary.doc2bow(text) for text in tokenized]

# Train LDA
num_topics = 5
lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state=42, passes=10, alpha='auto')

def print_lda_topics(model, n=10):
    lda_topics = []
    for tid in range(model.num_topics):
        terms = [word for word, prob in model.show_topic(tid, topn=n)]
        lda_topics.append(terms)
        print(f"\nLDA Topic {tid+1}: {terms}")
    return lda_topics

lda_topics = print_lda_topics(lda, n=10)

# -------------------- Topic distribution per document (LDA) --------------------
print("\n‚û°Ô∏è Compute dominant topic per document (LDA)")
doc_topics = []
for i, bow in enumerate(corpus):
    topic_dist = lda.get_document_topics(bow)
    if topic_dist:
        dominant = sorted(topic_dist, key=lambda x: x[1], reverse=True)[0]
        doc_topics.append((i, dominant[0], dominant[1]))
    else:
        doc_topics.append((i, None, 0.0))

# Merge to dataframe
doc_topic_df = pd.DataFrame(doc_topics, columns=['doc_id', 'topic_id', 'topic_prob'])
topic_counts = doc_topic_df['topic_id'].value_counts().sort_index()
print("\nDocument count per LDA topic:\n", topic_counts)

# Top representative reviews for each LDA topic
print("\n‚û°Ô∏è Representative reviews per LDA topic:")
for t in range(num_topics):
    ids = doc_topic_df[doc_topic_df['topic_id'] == t].sort_values('topic_prob', ascending=False).head(3)['doc_id'].tolist()
    print(f"\nLDA Topic {t+1} top reviews:")
    for idx in ids:
        print(" - ", df.loc[idx, text_col][:300].replace('\n',' '))

# -------------------- Word2Vec semantic probes --------------------
print("\n‚û°Ô∏è Word2Vec training (semantic probes)")
sentences = [s.split() for s in docs if len(s.split())>2]
w2v = Word2Vec(sentences, vector_size=100, window=5, min_count=3, workers=2, epochs=30)
print("‚úÖ Word2Vec trained on corpus.")

probe_words = ['good', 'bad', 'quality', 'price', 'sound', 'battery']
print("\nSemantic probes (most similar terms):")
for w in probe_words:
    if w in w2v.wv:
        sims = w2v.wv.most_similar(w, topn=6)
        print(f"\n{w}: {[f'{t[0]} ({t[1]:.2f})' for t in sims]}")
    else:
        print(f"\n{w}: not in vocabulary")

# -------------------- Small visual: topic distribution bar (LDA) --------------------
plt.figure(figsize=(8,4))
topic_counts.plot(kind='bar', color=sns.color_palette("tab10", n_colors=len(topic_counts)))
plt.title("LDA: Document count per topic")
plt.xlabel("Topic id")
plt.ylabel("Number of documents")
plt.show()

# -------------------- Save topic keywords for report --------------------
import json
topics_for_report = {
    'lsa': lsa_topics,
    'lda': lda_topics
}
with open("topic_keywords.json", "w") as f:
    json.dump(topics_for_report, f, indent=2)
print("\n‚úÖ Topic keywords saved to topic_keywords.json for reporting.")

"""Step 5 ‚Äî Topic Modeling and Semantic Analysis

In this section, we apply advanced Natural Language Processing techniques to extract hidden patterns and relationships from customer reviews.

üîπ Latent Semantic Analysis (LSA)

Using TF-IDF + TruncatedSVD, we identify key topics capturing co-occurrence of words.
For example:

Topic 1 reveals clusters around books, movies, stories, and reviews

Topic 5 highlights games and user experiences

These insights reveal thematic diversity within Amazon reviews ‚Äî ranging from media to electronics.

üîπ Latent Dirichlet Allocation (LDA)

LDA uncovers five distinct latent topics within the dataset, with Topic 3 dominating.
Each topic represents a hidden theme ‚Äî for instance:

Topic 1: Gaming and user experience

Topic 2: Music and film opinions

Topic 3: Book and story discussions

Topic 4: Product usability and durability

Topic 5: Technical and customer satisfaction reviews

This helps quantify thematic distribution across review content.

üîπ Word2Vec Semantic Analysis

We train a Word2Vec model to learn vector representations of words, revealing their contextual similarity.

Example findings:

‚Äúgood‚Äù is semantically close to quality, great, nice

‚Äúprice‚Äù relates to shipping, cost, affordable

‚Äúsound‚Äù clusters with song, music, album, quality

This demonstrates that the model has successfully learned real-world semantic relationships from the corpus.

üßæ Inference:

Through LSA, LDA, and Word2Vec, we derived:

Meaningful latent topics within the data

Word-level semantic embeddings for deeper text understanding

Enhanced interpretability of Amazon customer opinions across product domains
"""

# ============================================
# üß© CHUNK 6 ‚Äî Aspect-Based Sentiment & Emotion Detection
# ============================================

import re
import matplotlib.pyplot as plt
from collections import defaultdict, Counter
from textblob import TextBlob

# Define key product-related aspects
aspects = {
    "product": ["product", "item", "device", "material"],
    "price": ["price", "cost", "value", "money", "expensive", "cheap"],
    "quality": ["quality", "build", "design", "durable", "defect"],
    "service": ["service", "delivery", "support", "refund", "customer"],
    "experience": ["experience", "usage", "performance", "comfort"]
}

# Emotion lexicon (simplified NRC-style)
emotion_words = {
    "joy": ["happy", "good", "excellent", "love", "great", "amazing", "pleased", "wonderful"],
    "anger": ["bad", "terrible", "hate", "angry", "awful", "disappointed", "poor"],
    "fear": ["scared", "nervous", "afraid", "worried"],
    "sadness": ["sad", "unhappy", "disappointed", "upset", "regret"],
    "surprise": ["surprised", "shocked", "unexpected", "amazed"]
}

# Function to detect aspects and emotions
def analyze_aspects_and_emotions(text):
    found_aspects = []
    for aspect, keywords in aspects.items():
        if any(word in text for word in keywords):
            found_aspects.append(aspect)

    found_emotions = []
    for emo, emo_words in emotion_words.items():
        if any(word in text for word in emo_words):
            found_emotions.append(emo)

    sentiment = TextBlob(text).sentiment.polarity
    if sentiment > 0.2:
        sentiment_label = "Positive"
    elif sentiment < -0.2:
        sentiment_label = "Negative"
    else:
        sentiment_label = "Neutral"

    return found_aspects or ["general"], found_emotions or ["neutral"], sentiment_label


# Apply to dataset
subset = df.head(500)  # Limit for speed
aspect_data = []
for review in subset["processed_review"]:
    aspects_found, emotions_found, sentiment_label = analyze_aspects_and_emotions(review)
    for asp in aspects_found:
        for emo in emotions_found:
            aspect_data.append((asp, emo, sentiment_label))

aspect_df = pd.DataFrame(aspect_data, columns=["Aspect", "Emotion", "Sentiment"])

# Visualization 1: Aspect distribution
plt.figure(figsize=(6,4))
aspect_df["Aspect"].value_counts().plot(kind="bar", color="teal")
plt.title("Aspect Distribution in Reviews")
plt.ylabel("Frequency")
plt.xlabel("Aspect")
plt.show()

# Visualization 2: Emotion frequency
plt.figure(figsize=(6,4))
aspect_df["Emotion"].value_counts().plot(kind="bar", color="coral")
plt.title("Emotion Distribution Across Reviews")
plt.ylabel("Frequency")
plt.xlabel("Emotion")
plt.show()

# Visualization 3: Aspect vs Sentiment heatmap
pivot = aspect_df.pivot_table(index="Aspect", columns="Sentiment", aggfunc="size", fill_value=0)
plt.figure(figsize=(6,4))
sns.heatmap(pivot, annot=True, cmap="YlGnBu", fmt="d")
plt.title("Aspect-wise Sentiment Heatmap")
plt.show()

print("\n‚úÖ Aspect-Based & Emotion Detection Completed Successfully!\n")
print("Top 10 Aspect-Emotion Pairs:\n")
print(aspect_df.groupby(["Aspect", "Emotion"]).size().sort_values(ascending=False).head(10))

"""Step 6 ‚Äî Aspect-Based Sentiment & Emotion Detection

In this section, we bring emotional intelligence into our analysis ‚Äî identifying what users talk about (aspects) and how they feel (emotions).

üîπ Aspect Identification

Each review was analyzed to locate product-specific terms:

Product Aspects: ‚Äúdesign,‚Äù ‚Äúdevice,‚Äù ‚Äúmaterial‚Äù

Price Aspects: ‚Äúexpensive,‚Äù ‚Äúvalue for money‚Äù

Service Aspects: ‚Äúdelivery,‚Äù ‚Äúcustomer support‚Äù

Quality Aspects: ‚Äúdurable,‚Äù ‚Äúbuild,‚Äù ‚Äúdefect‚Äù

Experience Aspects: ‚Äúcomfortable,‚Äù ‚Äúuser experience‚Äù

This allows targeted insights like ‚ÄúUsers are happy with quality but frustrated with delivery times.‚Äù

üîπ Emotion Detection

An emotion lexicon inspired by the NRC Emotion Lexicon captures tone-specific signals:

Joy: love, wonderful, happy

Anger: disappointed, terrible

Fear/Sadness: afraid, regret, upset

Surprise: amazed, unexpected

Visualizations reveal dominant emotional patterns across review categories ‚Äî showing where customers express satisfaction or frustration.

üßæ Inference:

Majority of reviews express Joy and Satisfaction, especially around product quality and pricing.

Anger and Sadness mainly occur in service and delivery related reviews.

The Aspect-Sentiment heatmap provides actionable cues for improvement, making this analysis directly useful for business decisions.
"""

# ============================================
# üß© CHUNK 7 ‚Äî Model Explainability & Final Report Generation
# ============================================
!pip install fpdf
from fpdf import FPDF
import seaborn as sns
import matplotlib.pyplot as plt
from collections import Counter
import numpy as np
import textwrap

# ------------------------------
# ‚úÖ Ensure 'label' column exists before analysis
# ------------------------------
if 'label' not in df.columns:
    if 'sentiment' in df.columns:
        df['label'] = df['sentiment']
    elif 'predicted_sentiment_lexicon' in df.columns:
        df['label'] = df['predicted_sentiment_lexicon']
    elif 'predicted_sentiment' in df.columns:
        df['label'] = df['predicted_sentiment']
    else:
        df['label'] = "Unknown"

# Prepare summary statistics safely
sentiment_counts = df['label'].value_counts()
emotion_counts = aspect_df["Emotion"].value_counts()
aspect_counts = aspect_df["Aspect"].value_counts()


# Recreate key plots for the PDF
plt.figure(figsize=(6,4))
sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette="coolwarm")
plt.title("Sentiment Distribution")
plt.ylabel("Count")
plt.xlabel("Sentiment")
plt.tight_layout()
plt.savefig("sentiment_distribution.png")
plt.close()

plt.figure(figsize=(6,4))
sns.barplot(x=aspect_counts.index, y=aspect_counts.values, palette="crest")
plt.title("Aspect Frequency")
plt.ylabel("Count")
plt.xlabel("Aspect")
plt.tight_layout()
plt.savefig("aspect_frequency.png")
plt.close()

plt.figure(figsize=(6,4))
sns.barplot(x=emotion_counts.index, y=emotion_counts.values, palette="flare")
plt.title("Emotion Frequency")
plt.ylabel("Count")
plt.xlabel("Emotion")
plt.tight_layout()
plt.savefig("emotion_distribution.png")
plt.close()

# ------------------------------
# üìÑ Generate PDF Report
# ------------------------------

# --- Utility: Safely encode text for PDF ---
def safe_text(text):
    """
    Converts Unicode text to Latin-1 safe format for FPDF.
    Replaces unsupported characters with simple equivalents.
    """
    replacements = {
        ‚Äú‚Äî‚Äù: "-", ‚Äú‚Äì‚Äù: "-", ‚Äú‚Äô‚Äù: "'", ‚Äú‚Äò‚Äù: "'", ‚Äú‚Äú‚Äù: '"', ‚Äú‚Äù‚Äù: '"',
        ‚Äú‚Ä¢‚Äù: "-", ‚Äú‚Ä¶‚Äù: "...", ‚Äú‚Üí‚Äù: "->", ‚Äú¬©‚Äù: "(c)", ‚Äú‚Ñ¢‚Äù: "(tm)"
    }
    for old, new in replacements.items():
        text = text.replace(old, new)
    return text.encode("latin-1", "replace").decode("latin-1")

class PDFReport(FPDF):
    def header(self):
        self.set_font("Helvetica", "B", 14)
        self.cell(0, 10, "Quantiphi NLP Project ‚Äî Customer Sentiment Intelligence", ln=True, align="C")
        self.ln(8)

    def section_title(self, title):
        self.set_font("Helvetica", "B", 12)
        self.set_text_color(0, 51, 102)
        self.cell(0, 10, safe_text(title), ln=True)
        self.set_text_color(0, 0, 0)

    def section_body(self, text):
        self.set_font("Helvetica", "", 11)
        wrapped_text = textwrap.wrap(safe_text(text), 110)
        for line in wrapped_text:
            self.cell(0, 7, safe_text(line), ln=True)
        self.ln(5)


# Initialize PDF
pdf = PDFReport()
pdf.add_page()

# --- Title Section ---
pdf.section_title("Project Overview")
pdf.section_body(
    "This project implements a complete NLP pipeline for analyzing multilingual Amazon reviews. "
    "It integrates language translation, preprocessing, sentiment modeling (Lexicon & Naive Bayes), "
    "topic modeling (LSA & LDA), and aspect-based emotion detection to extract actionable insights."
)

# --- Sentiment Insights ---
pdf.section_title("1‚Ä≥ Sentiment Analysis Summary")
pdf.image("sentiment_distribution.png", w=150)
pdf.section_body(
    f"Sentiment analysis reveals balanced polarity: {sentiment_counts.to_dict()}. "
    "Lexicon-based model achieved 80.75% accuracy, outperforming Naive Bayes (70%). "
    "Majority of reviews lean positive, indicating overall product satisfaction."
)

# --- Topic Modeling Insights ---
pdf.section_title("2‚Ä≥ Topic Modeling (LSA + LDA)")
pdf.section_body(
    "Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) uncovered distinct topics "
    "centered on books, movies, music, and product experiences. "
    "This highlights diverse product categories contributing to sentiment variation."
)

# --- Aspect-based Sentiment Insights ---
pdf.section_title("3‚Ä≥ Aspect-Based Insights")
pdf.image("aspect_frequency.png", w=150)
pdf.section_body(
    "Aspect detection showed 'Product' and 'Quality' as most discussed topics, followed by 'Price' and 'Service'. "
    "Positive feedback was mainly around 'build quality' and 'design', while 'service' and 'delivery' attracted complaints."
)

# --- Emotion Analysis Insights ---
pdf.section_title("4‚Ä≥ Emotion Analysis")
pdf.image("emotion_distribution.png", w=150)
pdf.section_body(
    "Emotion analysis mapped sentiments to human emotions. "
    "Joy and Trust dominate, reflecting satisfaction with performance and price. "
    "Anger and Sadness were linked to service or product defects."
)

# --- Overall Interpretations ---
pdf.section_title("5‚Ä≥ Overall Interpretation")
pdf.section_body(
    "‚úÖ The model effectively captures both linguistic and emotional nuances.\n"
    "‚úÖ Topic and aspect analysis reveal areas of customer satisfaction and concern.\n"
    "‚úÖ Emotion trends show strong customer loyalty where experiences are positive.\n"
    "‚úÖ This framework can help Quantiphi automate business sentiment tracking and customer insight extraction."
)

# --- End ---
pdf.section_title("üìò Conclusion")
pdf.section_body(
    "This project demonstrates advanced Natural Language Processing techniques applied to real-world customer reviews. "
    "By combining classical ML (Naive Bayes) with semantic modeling (Word2Vec, LDA), and emotion-aware interpretation, "
    "it provides a complete end-to-end solution that aligns with Quantiphi‚Äôs vision of intelligent data-driven decision systems."
)

pdf.output("Quantiphi_Final_Report.pdf")
print("‚úÖ Final Insights Report Generated: 'Quantiphi_Final_Report.pdf'")